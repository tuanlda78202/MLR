# Machine Learning Research
<p align='left'>
  <a href="https://www.linkedin.com/in/tuanlda78202/">
    <img src="https://img.shields.io/badge/LinkedIn-%230077B5.svg?&style=flat&logo=linkedin&logoColor=white" />
  <a href="http://dsc-hust.club/members/details/246">
    <img src="https://img.shields.io/badge/GDSCxHUST-%23C1BDDA?style=flat&logo=GoogleColab&logoColor=black" />
  <a href="http://facebook.com/pageofhumanshust">
    <img src="https://img.shields.io/badge/Humans%20of%20HUST-FFDFD3?style=flat&logo=FACEBOOK&logoColor=black" />
  <a href="https://twitter.com/tuanlda78202">
    <img src="https://img.shields.io/badge/Twitter-%23daf6e5?style=flat&logo=twitter&logoColor=black" /> 
</p>

![GitHub commit activity](https://img.shields.io/github/commit-activity/m/tuanlda78202/MLR?color=%23F7CAC9&label=Commit&logo=Battle.net&logoColor=%23DFCFBE&style=flat-square) ![GitHub last commit](https://img.shields.io/github/last-commit/tuanlda78202/MLR?color=%23F7CAC9&label=Last%20Commit&logo=Google%20Photos&logoColor=%23DFCFBE&style=flat-square) ![GitHub repo size](https://img.shields.io/github/repo-size/tuanlda78202/MLR?color=%23F7CAC9&label=Repo%20Size&logo=Databricks&logoColor=%23DFCFBE&style=flat-square)
# 1. Project Topic

## 1.1. Existing research
- [**Connected Papers**](https://www.connectedpapers.com)

- [**Papers with Code**](https://paperswithcode.com/sota)
    
- [**Comprehensive Study**](https://www.google.com/search?q=comprehensive+study+%2B+%5Bdomain_research%5D&rlz=1C5CHFA_enVN982VN982&sxsrf=APq-WBu67O6q5l2uy1gLqFcfhd9SkCStaA%3A1646543668545&ei=NEMkYtHPIMHLmAX4hKWoCA&ved=0ahUKEwjRueGT3bD2AhXBJaYKHXhCCYUQ4dUDCA4&uact=5&oq=comprehensive+study+%2B+%5Bdomain_research%5D&gs_lcp=Cgdnd3Mtd2l6EAM6BwgAEEcQsAM6BggAEAgQHjoICAAQCBAHEB5KBAhBGABKBAhGGABQ5w1Y-Rlg9htoAXABeACAAZUCiAGgCpIBBTAuOC4xmAEAoAEByAEIwAEB&sclient=gws-wiz)
- [Google Scholar](http://scholar.google.com)

- [Science Direct](https://www.sciencedirect.com)
    
- [arXiv](http://arxiv.org/)

- [Sci-Hub](https://sci-hub.hkvisa.net)
   

- [Two Minute Papers](https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg)
    
- [Towards Data Science](https://towardsdatascience.com)

- [ACL NLP](http://www.aclweb.org/anthology/)
    
- [CVF](https://openaccess.thecvf.com/menu)
 
- [ACM](http://dl.acm.org/)

- [SOTA Report 2021](https://www.stateof.ai)

## 1.2. Datasets and Tasks

- [Huggingface Datasets](https://huggingface.co/datasets)
    
- [Kaggle Datasets](https://www.kaggle.com/datasets)
    
- [Wikipedia](https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research#Text_data) has a list of machine learning text datasets, tabulated with useful information such as dataset size
    
- [Datahub](https://datahub.io/collections) has lots of datasets, though not all of it is Machine Learning focused
        
- [Microsoft Research](https://www.microsoft.com/en-us/research/academic-program/data-science-microsoft-research) has a collection of datasets (look under the ‘Dataset directory’ tab)

- SOTA NLP:
        
    * [nlpprogress](https://nlpprogress.com/)
    
    * [gluebenchmark](https://gluebenchmark.com/leaderboard)
    
    * [conll](https://www.conll.org/previous-tasks)
    
- A small list of well-known standard datasets for common NLP tasks: 
    
    * [machinelearningmastery](https://machinelearningmastery.com/datasets-natural-language-processing)
- An alphabetical list of free or public domain text datasets:
    
    * [nlpdatasets](https://github.com/niderhoff/nlp-datasets)
    
- Datasets for machine translation:
    
    * [statmt](http://statmt.org/)
    
- Syntactic corpora for many languages:
    
    * [universaldependencies](https://universaldependencies.org/)
    
- A script to search arXiv papers for a keyword, and extract important information such as performance metrics on a task:
    
    * [huyenchip](https://huyenchip.com/2018/10/04/sotawhat.html)

## 1.13. Tools 
- [Overleaf](https://www.overleaf.com/project)
- [Mendeley](https://www.mendeley.com/search/)


# 2. Project Advice

## Processing Data

- [StanfordNLP](https://stanfordnlp.github.io/stanfordnlp/), a Python library providing tokenization, tagging, parsing, and other capabilities.
        
- Software from the [Stanford NLP Group](http://nlp.stanford.edu/software/index.shtml)
    
- [NLTK](http://nltk.org/), a lightweight Natural Language Toolkit package in Python.
    
- [spaCy](https://spacy.io/), another Python package that can do preprocessing, but also includes neural models (e.g. Language Models)    

# 3. Top Tiers ML&AI Conferences

- **Machine Learning**
    - [NeurIPS](https://nips.cc/)
      - Neural Information Processing Systems (formerly abbreviated NIPS). NeurIPS has gotten huge over the past few years as AI has become so important. Has a       focus on neural networks, but not exclusively.
    - [ICML](https://icml.cc/)
      - International Conference on Machine Learning. Has a general machine learning focus.
    - [ICLR](https://iclr.cc/)
      - International Conference on Learning Representations. ICLR was really the first conference focused on deep learning. It’s called “learning representations” because the motivation behind deep learning is to automatically learn higher-level features, or representations, that summarize data in useful ways. Deep Learning describes the structure of our current best solution to the problem of learning these representations.
    - [AISTATS](https://www.aistats.org/)

- **Computer Vision**
    - [CVPR](http://cvpr2019.thecvf.com/)
      - Computer Vision and Pattern Recognition.
    - [ICCV](http://iccv2019.thecvf.com/)
      - International Conference on Computer Vision.
    - [ECCV](https://eccv2020.eu/)
- **Natural Language Processing**
    - [ACL](http://www.acl2019.org/EN/index.xhtml)
    - [NAACL](https://naacl2019.org/)
    - [EMNLP](https://www.emnlp-ijcnlp2019.org/)
- **Data**
    - [KDD](https://www.kdd.org/)
    - [CIKM](http://www.cikmconference.org/)
    - [ICDM](http://icdm2019.bigke.org/)
    - [SDM](https://www.siam.org/Conferences/CM/Conference/sdm19)
    - [PAKDD](http://pakdd2019.medmeeting.org/)
    - [PKDD/ECML](http://ecmlpkdd2019.org/)
    - [RECSYS](https://recsys.acm.org/)
    - [SIGIR](https://sigir.org/)
    - [WWW](https://www2019.thewebconf.org/)
    - [WSDM](https://www.wsdm-conference.org/)
- **Artificial Intelligence**
    - [AAAI](https://www.aaai.org/)
      - Association for the Advancement of Artificial Intelligence. AAAI is a little more applications focused, and a little less theoretical than some of the other AI conferences.
    - [ICANN](https://e-nns.org/icann2019/)
    - [IJCAI](https://www.ijcai.org/)
     - [UAI](http://www.auai.org/)
# 4. Courses
* [Maths for Machine Learning](https://app.learney.me/maps/original_map#)
* [Applied Data Science with Python Specialization](https://www.coursera.org/specializations/data-science-python)
* [TensorFlow Developer Professional Certificate](https://www.coursera.org/professional-certificates/tensorflow-in-practice)
* [Google Data Analytics Professional Certificate](https://www.coursera.org/professional-certificates/google-data-analytics)
* [CS224W: Machine Learning with Graphs](https://web.stanford.edu/class/cs224w/?fbclid=IwAR15ClfPoL7mfylj6knvko-A_0uE06eFCZB4ZBOBFqwjwWjqYTafNkA-a1k)
* [CS230: Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning?)
* [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu)
