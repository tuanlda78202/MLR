# Machine Learning Research
<p align='left'>
  <a href="https://www.linkedin.com/in/tuanlda78202/">
    <img src="https://img.shields.io/badge/LinkedIn-%230077B5.svg?&style=flat&logo=linkedin&logoColor=white" />
  <a href="http://dsc-hust.club/members/details/246">
    <img src="https://img.shields.io/badge/GDSCxHUST-%23C1BDDA?style=flat&logo=GoogleColab&logoColor=black" />
  <a href="http://facebook.com/pageofhumanshust">
    <img src="https://img.shields.io/badge/Humans%20of%20HUST-FFDFD3?style=flat&logo=FACEBOOK&logoColor=black" />
  <a href="https://twitter.com/tuanlda78202">
    <img src="https://img.shields.io/badge/Twitter-%23daf6e5?style=flat&logo=twitter&logoColor=black" /> 
</p>

![GitHub commit activity](https://img.shields.io/github/commit-activity/m/tuanlda78202/MLR?color=%23F7CAC9&label=Commit&logo=Battle.net&logoColor=%23DFCFBE&style=flat-square) ![GitHub last commit](https://img.shields.io/github/last-commit/tuanlda78202/MLR?color=%23F7CAC9&label=Last%20Commit&logo=Google%20Photos&logoColor=%23DFCFBE&style=flat-square) ![GitHub repo size](https://img.shields.io/github/repo-size/tuanlda78202/MLR?color=%23F7CAC9&label=Repo%20Size&logo=Databricks&logoColor=%23DFCFBE&style=flat-square)
# 1. Project Topic

## 1.1. Exsiting research

- Benmark:
    
    [https://paperswithcode.com/sota](https://paperswithcode.com/sota)
    
- ACL anthology for NLP papers:
    
    [http://www.aclweb.org/anthology/](http://www.aclweb.org/anthology/)
    
- Online proceedings of major ML conferences:
    - [NeurIPS](https://papers.nips.cc/)
    - ICML, ICLR, CVPR, EMNLP, NAACL
- Online preprint servers:

   [http://arxiv.org/](http://arxiv.org/)
- Top paper menioned on Twitter:
    
    [http://www.arxiv-sanity.com/](http://www.arxiv-sanity.com/)
    
- Others:
    - [http://scholar.google.com](http://scholar.google.com/)
    - [http://dl.acm.org/](http://dl.acm.org/)
    - [http://aclasb.dfki.de](http://aclasb.dfki.de/)

## 1.2. Datasets and Tasks

- Huggingface Datasets:
    
    [https://huggingface.co/datasets](https://huggingface.co/datasets)
    
- Kaggle has many datasets, though some of them are too small for Deep Learning:
    
    [https://www.kaggle.com/datasets](https://www.kaggle.com/datasets)
    
- SOTA NLP:
    
    [https://paperswithcode.com/sota](https://paperswithcode.com/sota)
    
    [https://nlpprogress.com/](https://nlpprogress.com/)
    
    [https://gluebenchmark.com/leaderboard](https://gluebenchmark.com/leaderboard)
    
    [https://www.conll.org/previous-tasks](https://www.conll.org/previous-tasks)
    
- A small list of well-known standard datasets for common NLP tasks: [https://machinelearningmastery.com/datasets-natural-language-processing/](https://machinelearningmastery.com/datasets-natural-language-processing/)
- An alphabetical list of free or public domain text datasets:
    
    [https://github.com/niderhoff/nlp-datasets](https://github.com/niderhoff/nlp-datasets)
    
- Wikipedia has a list of machine learning text datasets, tabulated with useful information such as dataset size:
[https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research#Text_data](https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research#Text_data)
- Datahub has lots of datasets, though not all of it is Machine Learning focused:
    
    [https://datahub.io/collections](https://datahub.io/collections)
    
- Microsoft Research has a collection of datasets (look under the ‘Dataset directory’ tab):
[https://www.microsoft.com/en-us/research/academic-program/data-science-microsoft-research/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fprojects%2Fdata-science-initiative%2F%20datasets.aspx#!dataset-directory](https://www.microsoft.com/en-us/research/academic-program/data-science-microsoft-research/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fprojects%2Fdata-science-initiative%2F%2520datasets.aspx#!dataset-directory)
- A script to search arXiv papers for a keyword, and extract important information such as performance metrics on a task:
    
    [https://huyenchip.com/2018/10/04/sotawhat.html](https://huyenchip.com/2018/10/04/sotawhat.html)
    
- Datasets for machine translation:
    
    [http://statmt.org](http://statmt.org/)
    
- Syntactic corpora for many languages:
    
    [https://universaldependencies.org](https://universaldependencies.org/)
    

# 2. Project Advice

## Processing Data

- StanfordNLP: a Python library providing tokenization, tagging, parsing, and other capabilities:
    
    [https://stanfordnlp.github.io/stanfordnlp/](https://stanfordnlp.github.io/stanfordnlp/)
    
- Other software from the Stanford NLP group:
[http://nlp.stanford.edu/software/index.shtml](http://nlp.stanford.edu/software/index.shtml)
- NLTK, a lightweight Natural Language Toolkit package in Python:
[http://nltk.org/](http://nltk.org/)
- spaCy, another Python package that can do preprocessing, but also includes neural models (e.g. Language Models):
    
    [https://spacy.io/](https://spacy.io/)
    

# 3. Top Tiers ML&AI Conferences

- Site
    - ML
        - [NeurIPS](https://nips.cc/)
        - [ICML](https://icml.cc/)
        - [ICLR](https://iclr.cc/)
    - CV
        - [CVPR](http://cvpr2019.thecvf.com/)
        - [ICCV](http://iccv2019.thecvf.com/)
        - [ECCV](https://eccv2020.eu/)
    - NLP
        - [ACL](http://www.acl2019.org/EN/index.xhtml)
        - [NAACL](https://naacl2019.org/)
        - [EMNLP](https://www.emnlp-ijcnlp2019.org/)
    - Data
        - [KDD](https://www.kdd.org/)
        - [CIKM](http://www.cikmconference.org/)
        - [ICDM](http://icdm2019.bigke.org/)
        - [SDM](https://www.siam.org/Conferences/CM/Conference/sdm19)
        - [PAKDD](http://pakdd2019.medmeeting.org/)
        - [PKDD/ECML](http://ecmlpkdd2019.org/)
        - [RECSYS](https://recsys.acm.org/)
        - [SIGIR](https://sigir.org/)
        - [WWW](https://www2019.thewebconf.org/)
        - [WSDM](https://www.wsdm-conference.org/)
    - AI
        - [AAAI](https://www.aaai.org/)
        - [AISTATS](https://www.aistats.org/)
        - [ICANN](https://e-nns.org/icann2019/)
        - [IJCAI](https://www.ijcai.org/)
        - [UAI](http://www.auai.org/)
- **NeurIPS**: *Neural Information Processing Systems (formerly abbreviated NIPS). NeurIPS has gotten huge over the past few years as AI has become so important. Has a focus on neural networks, but not exclusively.*
    
     [https://nips.cc](https://nips.cc/)
    
- **ICML**: *International Conference on Machine Learning. Has a general machine learning focus.*
    
    [https://icml.cc](https://icml.cc/)
    
- **ICLR**: *International Conference on Learning Representations. ICLR was really the first conference focused on deep learning. It’s called “learning representations” because the motivation behind deep learning is to automatically learn higher-level features, or representations, that summarize data in useful ways. Deep Learning describes the structure of our current best solution to the problem of learning these representations.*
    
     [https://iclr.cc](https://iclr.cc/)
    
- **AAAI**: *Association for the Advancement of Artificial Intelligence. AAAI is a little more applications focused, and a little less theoretical than some of the other AI conferences.*
    
    [http://www.aaai.org](http://www.aaai.org/)
    
- **CVPR**: *Computer Vision and Pattern Recognition.*
    
    [https://www.thecvf.com](https://www.thecvf.com/)
    
- **ICCV**: *International Conference on Computer Vision.*
    
    [https://www.thecvf.com](https://www.thecvf.com/)

# 4. Reference 
[Practical Tips for Final Projects Notes](https://web.stanford.edu/class/cs224n/readings/final-project-practical-tips.pdf)

[List of great ML/AI conferences](https://www.kaggle.com/getting-started/115799)
